{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying `Series`\n",
    "\n",
    "In this lecture, we'll talk about one of the primary data types of the Pandas library, the Series. You'll learn about the structure of the Series, how to query and merge Series objects together, and the importance of thinking about parallelization when engaging in data science programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pandas Series can be queried either by the index position or the index label. If you don't give an \n",
    "# index to the series when querying, the position and the label are effectively the same values. To \n",
    "# query by numeric location, starting at zero, use the iloc attribute. To query by the index label, \n",
    "# you can use the loc attribute. \n",
    "\n",
    "# Lets start with an example. We'll use students enrolled in classes coming from a dictionary\n",
    "import pandas as pd\n",
    "students_classes = {'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, for this series, if you wanted to see the fourth entry we would we would use the iloc \n",
    "# attribute with the parameter 3.\n",
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n",
      "Alice\n",
      "Physics\n",
      "Physics\n"
     ]
    }
   ],
   "source": [
    "print(s['Alice'])\n",
    "print(s.index[0])\n",
    "print(s.iloc[0])\n",
    "print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you wanted to see what class Molly has, we would use the loc attribute with a parameter \n",
    "# of Molly.\n",
    "s.loc['Molly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that iloc and loc are not methods, they are attributes. So you don't use \n",
    "# parentheses to query them, but square brackets instead, which is called the indexing operator. \n",
    "# In Python this calls get or set for an item depending on the context of its use.\n",
    "\n",
    "# This might seem a bit confusing if you're used to languages where encapsulation of attributes, \n",
    "# variables, and properties is common, such as in Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas tries to make our code a bit more readable and provides a sort of smart syntax using \n",
    "# the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, \n",
    "# the operator will behave as if you want it to query via the iloc attribute\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you pass in an object, it will query as if you wanted to use the label based loc attribute.\n",
    "s['Molly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what happens if your index is a list of integers? This is a bit complicated and Pandas can't \n",
    "# determine automatically whether you're intending to query by index position or index label. So \n",
    "# you need to be careful when using the indexing operator on the Series itself. The safer option \n",
    "# is to be more explicit and use the iloc or loc attributes directly.\n",
    "\n",
    "# Here's an example using class and their classcode information, where classes are indexed by \n",
    "# classcodes, in the form of integers\n",
    "class_code = {99: 'Physics',\n",
    "              100: 'Chemistry',\n",
    "              101: 'English',\n",
    "              102: 'History'}\n",
    "s = pd.Series(class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_7736\\455575107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# an index of zero, instead we have to call iloc explicitly if we want the first item.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# If we try and call s[0] we get a key error because there's no item in the classes list with \n",
    "# an index of zero, instead we have to call iloc explicitly if we want the first item.\n",
    "\n",
    "s[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, that didn't call s.iloc[0] underneath as one might expect, instead it \n",
    "# generates an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know how to get data out of the series, let's talk about working with the data. A common \n",
    "# task is to want to consider all of the values inside of a series and do some sort of \n",
    "# operation. This could be trying to find a certain number, or summarizing data or transforming \n",
    "# the data in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# A typical programmatic approach to this would be to iterate over all the items in the series, \n",
    "# and invoke the operation one is interested in. For instance, we could create a Series of \n",
    "# integers representing student grades, and just try and get an average grade\n",
    "\n",
    "grades = pd.Series([90, 80, 70, 60])\n",
    "\n",
    "total = 0\n",
    "for grade in grades:\n",
    "    total+=grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works, but it's slow. Modern computers can do many tasks simultaneously, especially, \n",
    "# but not only, tasks involving mathematics.\n",
    "\n",
    "# Pandas and the underlying numpy libraries support a method of computation called vectorization. \n",
    "# Vectorization works with most of the functions in the numpy library, including the sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# Here's how we would really write the code using the numpy sum method. First we need to import \n",
    "# the numpy module\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Then we just call np.sum and pass in an iterable item. In this case, our panda series.\n",
    "\n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    437\n",
       "1    409\n",
       "2    540\n",
       "3    115\n",
       "4    753\n",
       "dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now both of these methods create the same value, but is one actually faster? The Jupyter \n",
    "# Notebook has a magic function which can help. \n",
    "\n",
    "# First, let's create a big series of random numbers. This is used a lot when demonstrating \n",
    "# techniques with Pandas\n",
    "numbers = pd.Series(np.random.randint(0,1000,10000))\n",
    "\n",
    "# Now lets look at the top five items in that series to make sure they actually seem random. We\n",
    "# can do this with the head() function\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can actually verify that length of the series is correct using the len function\n",
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we're confident now that we have a big series. The ipython interpreter has something called\n",
    "# magic functions begin with a percentage sign. If we type this sign and then hit the Tab key, you\n",
    "# can see a list of the available magic functions. You could write your own magic functions too, \n",
    "# but that's a little bit outside of the scope of this course.\n",
    "\n",
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're actually going to use what's called a cellular magic function. These start with two \n",
    "# percentage signs and wrap the code in the current Jupyter cell. The function we're going to use \n",
    "# is called timeit. This function will run our code a few times to determine, on average, how long \n",
    "# it takes.\n",
    "\n",
    "# Let's run timeit with our original iterative code. You can give timeit the number of loops that \n",
    "# you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because \n",
    "# we're recording this. Note that in order to use a cellular magic function, it has to be the first \n",
    "# line in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968 µs ± 129 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total+=number\n",
    "\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not bad. Timeit ran the code and it doesn't seem to take very long at all. Now let's try with \n",
    "# vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.8 µs ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow! This is a pretty shocking difference in the speed and demonstrates why one should be \n",
    "# aware of parallel computing features and start thinking in functional programming terms.\n",
    "# Put more simply, vectorization is the ability for a computer to execute multiple instructions\n",
    "# at once, and with high performance chips, especially graphics cards, you can get dramatic\n",
    "# speedups. Modern graphics cards can run thousands of instructions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    437\n",
       "1    409\n",
       "2    540\n",
       "3    115\n",
       "4    753\n",
       "dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Related feature in pandas and nummy is called broadcasting. With broadcasting, you can \n",
    "# apply an operation to every value in the series, changing the series. For instance, if we\n",
    "# wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
    "# directly on the Series object. \n",
    "\n",
    "# Let's look at the head of our series\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    439\n",
       "1    411\n",
       "2    542\n",
       "3    117\n",
       "4    755\n",
       "dtype: int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now lets just increase everything in the series by 2\n",
    "numbers+=2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    441\n",
       "1    413\n",
       "2    544\n",
       "3    119\n",
       "4    757\n",
       "dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The procedural way of doing this would be to iterate through all of the items in the \n",
    "# series and increase the values directly. Pandas does support iterating through a series \n",
    "# much like a dictionary, allowing you to unpack values easily.\n",
    "\n",
    "# We can use the iteritems() function which returns a label and value \n",
    "for label, value in numbers.iteritems():\n",
    "    # in the early version of pandas we would use the set_value() function\n",
    "    # in the current version, we use the iat() or at() functions,\n",
    "    numbers.iat[label]= value+2\n",
    "# And we can check the result of this computation\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the result is the same, though you may notice a warning depending upon the version of\n",
    "# pandas being used. But if you find yourself iterating pretty much *any time* in pandas,\n",
    "# you should question whether you're doing things in the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at some speed comparisons. First, lets try five loops using the iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.8 ms ± 4.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# we'll create a blank new series of items to deal with\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we'll just rewrite our loop from above.\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try that using the broadcasting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 µs ± 51.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# We need to recreate a series\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we just broadcast with +=\n",
    "s+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazing. Not only is it significantly faster, but it's more concise and even easier \n",
    "# to read too. The typical mathematical operations you would expect are vectorized, and the \n",
    "# nump documentation outlines what it takes to create vectorized functions of your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last note on using the indexing operators to access series data. The .loc attribute lets \n",
    "# you not only modify data in place, but also add new data as well. If the value you pass in as \n",
    "# the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
    "# While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
    "# change the underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "History    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example using a Series of a few numbers. \n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# We could add some new value, maybe a university course\n",
    "s.loc['History'] = 102\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that mixed types for data values or index labels are no problem for Pandas. Since \n",
    "# \"History\" is not in the original list of indices, s.loc['History'] essentially creates a \n",
    "# new element in the series, with the index named \"History\", and the value of 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Up until now I've shown only examples of a series where the index values were unique. I want \n",
    "# to end this lecture by showing an example where index values are not unique, and this makes \n",
    "# pandas Series a little different conceptually then, for instance, a relational database.\n",
    "\n",
    "# Lets create a Series with students and the courses which they have taken\n",
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'})\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets create a Series just for some new student Kelly, which lists all of the courses\n",
    "# she has taken. We'll set the index to Kelly, and the data to be the names of courses.\n",
    "kelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E073016\\AppData\\Local\\Temp\\1\\ipykernel_7736\\2260173025.py:3: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_students_classes = students_classes.append(kelly_classes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we can append all of the data in this new Series to the first using the .append()\n",
    "# function.\n",
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "\n",
    "# This creates a series which has our original people in it as well as all of Kelly's courses\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a couple of important considerations when using append. First, Pandas will take \n",
    "# the series and try to infer the best data types to use. In this example, everything is a string, \n",
    "# so there's no problems here. Second, the append method doesn't actually change the underlying Series\n",
    "# objects, it instead returns a new series which is made up of the two appended together. This is\n",
    "# a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
    "# one you should come to expect. By printing the original series we can see that that series hasn't\n",
    "# changed.\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we see that when we query the appended series for Kelly, we don't get a single value, \n",
    "# but a series itself. \n",
    "all_students_classes.loc['Kelly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we focused on one of the primary data types of the Pandas library, the Series. You learned how to query the Series, with .loc and .iloc, that the Series is an indexed data structure, how to merge two Series objects together with append(), and the importance of vectorization.\n",
    "\n",
    "There are many more methods associated with the Series object that we haven't talked about. But with these basics down, we'll move on to talking about the Panda's two-dimensional data structure, the DataFrame. The DataFrame is very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
